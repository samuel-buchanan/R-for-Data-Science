---
title: 'Data Analysis Assignment #2'
author: "Buchanan, Samuel"
date: "August 18, 2019"
output: html_document
---


```{r setup, include = FALSE}
# DO NOT ADD OR REVISE CODE HERE
knitr::opts_chunk$set(echo = FALSE, eval = TRUE)

```

### Instructions

R markdown is a plain-text file format for integrating text and R code, and creating transparent, reproducible and interactive reports. An R markdown file (.Rmd) contains metadata, markdown and R code "chunks", and can be "knit" into numerous output types. Answer the test questions by adding R code to the fenced code areas below each item. There are questions that require a written answer that also need to be answered. Enter your comments in the space provided as shown below:

***Answer: (Enter your answer here.)*** 

Once completed, you will "knit" and submit the resulting .html document and the .Rmd file. The .html will present the output of your R code and your written answers, but your R code will not appear.  Your R code will appear in the .Rmd file. The resulting .html document will be graded and a feedback report returned with comments.  Points assigned to each item appear in the template.

**Before proceeding, look to the top of the .Rmd for the (YAML) metadata block, where the *title*, *author* and *output* are given. Please change *author* to include your name, with the format 'lastName, firstName.'**

If you encounter issues with knitting the .html, please send an email via Canvas to your TA.

Each code chunk is delineated by six (6) backticks; three (3) at the start and three (3) at the end. After the opening ticks, arguments are passed to the code chunk and in curly brackets. **Please do not add or remove backticks, or modify the arguments or values inside the curly brackets**. An example code chunk is included here: 

```{r exampleCodeChunk, eval = FALSE, echo = TRUE}
# Comments are included in each code chunk, simply as prompts

#...R code placed here

#...R code placed here

```

R code only needs to be added inside the code chunks for each assignment item. However, there are questions that follow many assignment items. Enter your answers in the space provided. An example showing how to use the template and respond to a question follows.

-----

**Example Problem with Solution:**

Use *rbinom()* to generate two random samples of size 10,000 from the binomial distribution. For the first sample, use p = 0.45 and n = 10. For the second sample, use p = 0.55 and n = 10. Convert the sample frequencies to sample proportions and compute the mean number of successes for each sample. Present these statistics.

```{r Example, eval = TRUE, echo = TRUE}

set.seed(123)
sample.one <- table(rbinom(10000, 10, 0.45)) / 10000
sample.two <- table(rbinom(10000, 10, 0.55)) / 10000

successes <- seq(0, 10)

round(sum(sample.one*successes), digits = 1) # [1] 4.5
round(sum(sample.two*successes), digits = 1) # [1] 5.5
```

**Question: How do the simulated expectations compare to calculated binomial expectations?**

***Answer:  The calculated binomial expectations are 10(0.45) = 4.5 and 10(0.55) = 5.5.  After rounding the simulated results, the same values are obtained.***

-----

Submit both the .Rmd and .html files for grading. You may remove the instructions and example problem above, but do not remove the YAML metadata block or the first, "setup" code chunk.  Address the steps that appear below and answer all the questions. Be sure to address each question with code and comments as needed.  You may use either base R functions or ggplot2 for the visualizations.

-----

##Data Analysis #2

```{r analysis_setup1, message = FALSE, warning = FALSE}

# Perform the following steps to start the assignment.
 
# 1) Load/attach the following packages via library():  flux, ggplot2, gridExtra, moments, rockchalk, car.
# NOTE:  packages must be installed via install.packages() before they can be loaded.

library(flux)
library(ggplot2)
library(gridExtra)
library(moments)
# library(rockchalk) # base R code replaces requirement for this package
library(car)

# 2) Use the "mydata.csv" file from Assignment #1 or use the file posted on the course site.  Reading
# the files into R will require sep = "" or sep = " " to format data properly.  Use str() to check file
# structure.

mydata <- read.csv("mydata2.csv", sep = ",")
# mydata <- read.csv(file.path("c:...", "mydata.csv"), sep = ",")
# mydata <- read.csv(file.path("c:/Rabalone/", "mydata.csv"), sep = ",")

str(mydata)

```

### Test Items starts from here - There are 10 sections - total of 75 points ##############

##### Section 1: (5 points)

(1)(a) Form a histogram and QQ plot using RATIO. Calculate skewness and kurtosis using 'rockchalk.' Be aware that with 'rockchalk', the kurtosis value has 3.0 subtracted from it which differs from the 'moments' package. 

```{r Part_1a}

hist(mydata$RATIO, xlab = "Ratio")

qqnorm(mydata$RATIO, main = "QQ plot of Ratio")
qqline(mydata$RATIO, col = "red")

skewness(mydata$RATIO)
kurtosis(mydata$RATIO)
```

(1)(b) Tranform RATIO using *log10()* to create L_RATIO (Kabacoff Section 8.5.2, p. 199-200). Form a histogram and QQ plot using L_RATIO. Calculate the skewness and kurtosis. Create a boxplot of L_RATIO differentiated by CLASS.

```{r Part_1b}
mydata$L_RATIO <- log10(mydata$RATIO)

hist(mydata$L_RATIO, xlab = "Ratio")

qqnorm(mydata$L_RATIO, main = "QQ plot of Ratio")
qqline(mydata$L_RATIO, col = "red")

skewness(mydata$L_RATIO)
kurtosis(mydata$L_RATIO)

boxplot(L_RATIO ~ CLASS, data = mydata)

```

(1)(c) Test the homogeneity of variance across classes using *bartlett.test()* (Kabacoff Section 9.2.2, p. 222). 

```{r Part_1c}
bartlett.test(L_RATIO ~ CLASS, data = mydata)
bartlett.test(RATIO ~ CLASS, data = mydata)


```

**Essay Question: Based on steps 1.a, 1.b and 1.c, which variable RATIO or L_RATIO exhibits better conformance to a normal distribution with homogeneous variances across age classes?  Why?** 

***Answer: (The transformed data seems to be more normal and exhibit more homogenous variance across the classes. The Bartlett test can't reject the null hypothesis of each group having the same variance in the transformed group, unlike the regular ratio. Furthermore, the skewedness is less for the transformed group.)***


##### Section 2 (10 points) ###############################

(2)(a) Perform an analysis of variance with *aov()* on L_RATIO using CLASS and SEX as the independent variables (Kabacoff chapter 9, p. 212-229). Assume equal variances. Perform two analyses. First, fit a model with the interaction term CLASS:SEX. Then, fit a model without CLASS:SEX. Use *summary()* to obtain the analysis of variance tables (Kabacoff chapter 9, p. 227).

```{r Part_2a}
summary(aov(L_RATIO ~ CLASS + SEX + CLASS:SEX, data = mydata))
summary(aov(L_RATIO ~ CLASS + SEX, data = mydata))



```

**Essay Question:  Compare the two analyses.  What does the non-significant interaction term suggest about the relationship between L_RATIO and the factors CLASS and SEX?**

***Answer: (While both SEX and CLASS individually are significantly associated with the L_RATIO variable, adding in the combination of the two does not seem to produce significant results. So individually SEX and CLASS seem to covary, the two together do not produce and improvement in the significance. )***

(2)(b) For the model without CLASS:SEX (i.e. an interaction term), obtain multiple comparisons with the *TukeyHSD()* function. Interpret the results at the 95% confidence level (*TukeyHSD()* will adjust for unequal sample sizes). 

```{r Part_2b}
TukeyHSD(aov(L_RATIO ~ CLASS + SEX, data = mydata))

```

**Additional Essay Question:  first, interpret the trend in coefficients across age classes. What is this indicating about L_RATIO?  Second, do these results suggest male and female abalones can be combined into a single category labeled as 'adults?' If not, why not?**

***Answer: (To me, it looks like only the youngest classes (A2-A1) do not vary significantly by the transformed ratio. At the p < 0.05 level, all the other classes do. This points to CLASS overall being a very good indicator of the ratio. As for the sex, the male and female together are not at all significant which suggests that if the two were combined it wouldn't make much difference as far as the ratio is concerned.)***


######  Section 3: (10 points) ##################

(3)(a1) We combine "M" and "F" into a new level, "ADULT". (While this could be accomplished using *combineLevels()* from the 'rockchalk' package, we use base R code because many students do not have access to the rockchalk package.) This necessitated defining a new variable, TYPE, in mydata which had two levels:  "I" and "ADULT". 

```{r Part_3a1}
# here we show how to define the new variable TYPE using only base R functions (no need for outside packages)
mydata$TYPE <- character(nrow(mydata))  # initialize the TYPE column as all blanks
for (i in seq(along = mydata$SEX)) {
  mydata$TYPE[i] <- 'I'
  if (mydata$SEX[i] == 'M' || mydata$SEX[i] == 'F') mydata$TYPE[i] <- 'ADULT'
}
mydata$TYPE <- factor(mydata$TYPE)
cat('\nCheck on definition of TYPE object (should be an integer): ', typeof(mydata$TYPE))
cat('\nmydata$TYPE is treated as a factor: ', is.factor(mydata$TYPE), '\n')
table(mydata$SEX, mydata$TYPE)

```
(3)(a2)  Present side-by-side histograms of VOLUME. One should display infant volumes and, the other, adult volumes. 

```{r Part_3a2}
par(mfrow = c(1, 2))

hist(mydata$VOLUME[mydata$TYPE == "I"], main = "Infant volumes")
hist(mydata$VOLUME[mydata$TYPE == "ADULT"], main = "M+F volumes")

```


**Essay Question: Compare the histograms.  How do the distributions differ? Are there going to be any difficulties separating infants from adults based on VOLUME?**

***Answer: (Infant volumes are heavily right-skewed, as would be expected. M+F volumes are more normal as you would also expect for a population measurement. I don't think it should be difficult at all to separate the two populations types based on volume.)***

(3)(b) Create a scatterplot of SHUCK versus VOLUME and a scatterplot of their base ten logarithms, labeling the variables as L_SHUCK and L_VOLUME. Please be aware the variables, L_SHUCK and L_VOLUME, present the data as orders of magnitude (i.e. VOLUME = 100 = 10^2 becomes L_VOLUME = 2). Use color to differentiate CLASS in the plots. Repeat using color to differentiate by TYPE. 

```{r Part_3b}
mydata$L_SHUCK <- log10(mydata$SHUCK)
mydata$L_VOLUME <- log10(mydata$VOLUME)


plot(SHUCK ~ VOLUME, data = mydata, col = c("lightblue", "darkred", "orange", "green", "pink")[mydata$CLASS])
plot(L_SHUCK ~ L_VOLUME, data = mydata, col = c("lightblue", "darkred", "orange", "green", "pink")[mydata$CLASS])
plot(SHUCK ~ VOLUME, data = mydata, col = c("red", "green")[mydata$TYPE])
plot(L_SHUCK ~ L_VOLUME, data = mydata, col = c("red", "green")[mydata$TYPE])
```

**Additional Essay Question:  Compare the two scatterplots. What effect(s) does log-transformation appear to have on the variability present in the plot?  What are the implications for linear regression analysis? Where do the various CLASS levels appear in the plots? Where do the levels of TYPE appear in the plots?**

***Answer: (The variability of the transformed data seems to be flattened compared to the normal data. This should make linear regression more predictive when using the transformed data. The levels appear in order just as would be expected, with the more advanced classes appearing higher on the volume chart. This is somewhat easier to tell on the transformed graphs, as the increased variability in the raw data makes seeing relationships like these more difficult.)***


######   Section 4: (5 points) ###################################

(4)(a1) Since abalone growth slows after class A3, infants in classes A4 and A5 are considered mature and candidates for harvest. Reclassify the infants in classes A4 and A5 as ADULTS. This reclassification could have been achieved using *combineLevels()*, but only on the abalones in classes A4 and A5. We will do this recoding of the TYPE variable using base R functions. We will use this recoded TYPE variable, in which the infants in A4 and A5 are reclassified as ADULTS, for the remainder of this data analysis assignment. 

```{r Part_4a1}
for (i in seq(along = mydata$TYPE)) {
  if (mydata$CLASS[i] == 'A4' || mydata$CLASS[i] == 'A5') mydata$TYPE[i] <- 'ADULT'
}
mydata$TYPE <- factor(mydata$TYPE)
cat('\nCheck on redefinition of TYPE object (should be an integer): ', typeof(mydata$TYPE))
cat('\nmydata$TYPE is treated as a factor: ', is.factor(mydata$TYPE), '\n')
cat('\nThree-way contingency table for SEX, CLASS, and TYPE:\n')
print(table(mydata$SEX, mydata$CLASS, mydata$TYPE))
```

(4)(a2) Regress L_SHUCK as the dependent variable on L_VOLUME, CLASS and TYPE (Kabacoff Section 8.2.4, p. 178-186, the Data Analysis Video #2 and Black Section 14.2). Use the multiple regression model: L_SHUCK ~ L_VOLUME + CLASS + TYPE. Apply *summary()* to the model object to produce results.

```{r Part_4a2}


lin_model <- lm(L_SHUCK ~ L_VOLUME + CLASS + TYPE, data = mydata)
summary(lin_model)

```

**Essay Question:  Interpret the trend in CLASS levelcoefficient estimates? (Hint:  this question is not asking if the estimates are statistically significant. It is asking for an interpretation of the pattern in these coefficients, and how this pattern relates to the earlier displays).**

***Answer: (The pattern seems to be that the higher the class, the greater the predictive ability, with CLASSA5 having the smallest significance of all the variables tested. This agrees with the eariler statements in question 4 that abalones are done growing when in class 4 or 5 and have probably attained their maximum weight.)***

**Additional Essay Question:  Is TYPE an important predictor in this regression? (Hint:  This question is not asking if TYPE is statistically significant, but rather how it compares to the other independent variables in terms of its contribution to predictions of L_SHUCK for harvesting decisions.)  Explain your conclusion.**

***Answer: (TYPE is weakly predictive of L_SHUCK, but other variables are better. Of all the variables tested, it is the second worst in terms of significance so probably not the one you would want to base your predictions off of.)***

-----

The next two analysis steps involve an analysis of the residuals resulting from the regression model in (4)(a) (Kabacoff Section 8.2.4, p. 178-186, the Data Analysis Video #2).

-----

###### Section 5: (5 points) #################################

(5)(a) If "model" is the regression object, use model$residuals and construct a histogram and QQ plot. Compute the skewness and kurtosis. Be aware that with 'rockchalk,' the kurtosis value has 3.0 subtracted from it which differs from the 'moments' package. 

```{r Part_5a}
hist(lin_model$residuals)
qqnorm(lin_model$residuals, main = "QQ plot of Residuals")
qqline(lin_model$residuals, col = "red")


skewness(lin_model$residuals)
kurtosis(lin_model$residuals)
```

(5)(b) Plot the residuals versus L_VOLUME, coloring the data points by CLASS and, a second time, coloring the data points by TYPE. Keep in mind the y-axis and x-axis may be disproportionate which will amplify the variability in the residuals. Present boxplots of the residuals differentiated by CLASS and TYPE (These four plots can be conveniently presented on one page using *par(mfrow..)* or *grid.arrange()*. Test the homogeneity of variance of the residuals across classes using *bartlett.test()* (Kabacoff Section 9.3.2, p. 222).  

```{r Part_5b}
par(mfrow = c(2,2))

plot(lin_model$residuals ~ mydata$L_VOLUME, col = c("lightblue", "darkred", "orange", "green", "pink")[mydata$CLASS])
plot(lin_model$residuals ~ mydata$L_VOLUME, col = c("red", "black")[mydata$TYPE])

boxplot(lin_model$residuals ~ mydata$CLASS)
boxplot(lin_model$residuals ~ mydata$TYPE)

bartlett.test(lin_model$residuals ~ mydata$CLASS)

```

**Essay Question:  What is revealed by the displays and calculations in (5)(a) and (5)(b)? Does the model 'fit'?  Does this analysis indicate that L_VOLUME, and ultimately VOLUME, might be useful for harvesting decisions? Discuss.**  

***Answer: (The residuals are fairly evenly distirbuted, which carries through by CLASS or TYPE. Aside from a few outliers, it would be difficult to tell them apart. Judging from the normal-shaped residuals histogram and the QQ plot, the model seems to fit fairly well. This goes along with the Bartlett test score as well.)***

-----

There is a tradeoff faced in managing abalone harvest. The infant population must be protected since it represents future harvests. On the other hand, the harvest should be designed to be efficient with a yield to justify the effort. This assignment will use VOLUME to form binary decision rules to guide harvesting. If VOLUME is below a "cutoff" (i.e. a specified volume), that individual will not be harvested. If above, it will be harvested. Different rules are possible.

The next steps in the assignment will require consideration of the proportions of infants and adults harvested at different cutoffs. For this, similar "for-loops" will be used to compute the harvest proportions. These loops must use the same values for the constants min.v and delta and use the same statement "for(k in 1:10000)."  Otherwise, the resulting infant and adult proportions cannot be directly compared and plotted as requested. Note the example code supplied below.

-----

#### Section 6: (5 points) ########################

(6)(a) A series of volumes covering the range from minimum to maximum abalone volume will be used in a "for loop" to determine how the harvest proportions change as the "cutoff" changes. Code for doing this is provided.

```{r Part_6a}

idxi <- mydata$TYPE == "I"
idxa <- mydata$TYPE == "ADULT"

max.v <- max(mydata$VOLUME)
min.v <- min(mydata$VOLUME)
delta <- (max.v - min.v)/10000
prop.infants <- numeric(10000)
prop.adults <- numeric(10000)
volume.value <- numeric(10000)

total.infants <- sum(idxi)  
total.adults <- sum(idxa)

for (k in 1:10000) { 
	value <- min.v + k*delta
	volume.value[k] <- value
	prop.infants[k] <- sum(mydata$VOLUME[idxi] <= value)/total.infants
	prop.adults[k] <-  sum(mydata$VOLUME[idxa] <= value)/total.adults
}

# prop.infants shows the impact of increasing the volume cutoff for
# harvesting. The following code shows how to "split" the population at
# a 50% harvest of infants.

n.infants <- sum(prop.infants <= 0.5)
split.infants <- min.v + (n.infants + 0.5)*delta  # This estimates the desired volume.
split.infants

n.adults <- sum(prop.adults <= 0.5)
split.adults <- min.v + (n.adults + 0.5)*delta
split.adults

```

(6)(b) Present a plot showing the infant proportions and the adult proportions versus volume.value. Compute the 50% "split" volume.value for each and show on the plot.   

```{r Part_6b}
plot(prop.infants ~ volume.value, col = "darkgreen")
par(new = TRUE)
plot(prop.adults ~ volume.value, col = "blue", ylab = "")
abline(h = 0.5, v = c(split.infants, split.adults))


```

**Essay Question:  The two 50% "split" values serve a descriptive purpose illustrating the difference between the populations. What do these values suggest regarding possible cutoffs for harvesting?** 

***Answer: (The split values show that there is good separation between the groups. In the adult proportion, you only get maybe less than 10% of the infant population and likewise in the opposite case. Given the variables present, I don't think a better alternative exists.)***

-----

This part will address the determination of a volume.value corresponding to the observed maximum difference in harvest percentages of adults and infants. To calculate this result, the vectors of proportions from item (6) must be used. These proportions must be converted from "not harvested" to "harvested" proportions by using (1 - prop.infants) for infants, and (1 - prop.adults) for adults. The reason the proportion for infants drops sooner than adults is that infants are maturing and becoming adults with larger volumes.

-----

###### Section 7: (10 points)  #######################

(7)(a) Evaluate a plot of the difference ((1 - prop.adults) - (1 - prop.infants)) versus volume.value. Compare to the 50% "split" points determined in (6)(a). There is considerable variability present in the peak area of this plot. The observed "peak" difference may not be the best representation of the data. One solution is to smooth the data to determine a more representative estimate of the maximum difference.

```{r Part_7a}
plot(((1 - prop.adults) - (1 - prop.infants))~volume.value)
abline(v = c(split.infants, split.adults))


```

(7)(b) Since curve smoothing is not studied in this course, code is supplied below. Execute the following code to create a smoothed curve to append to the plot in (a). The procedure is to individually smooth (1-prop.adults) and (1-prop.infants) before determining an estimate of the maximum difference. 

```{r Part_7b}

y.loess.a <- loess(1 - prop.adults ~ volume.value, span = 0.25,
	family = c("symmetric"))
y.loess.i <- loess(1 - prop.infants ~ volume.value, span = 0.25,
	family = c("symmetric"))
smooth.difference <- predict(y.loess.a) - predict(y.loess.i)

```

(7)(c) Present a plot of the difference ((1 - prop.adults) - (1 - prop.infants)) versus volume.value with the variable smooth.difference superimposed. Determine the volume.value corresponding to the maximum smoothed difference (Hint:  use *which.max()*). Show the estimated peak location corresponding to the cutoff determined.

```{r Part_7c}
plot(((1 - prop.adults) - (1 - prop.infants))~volume.value, xlim = c(0, 1000), ylim = c(0, 0.7))
par(new = TRUE)
plot(smooth.difference ~ volume.value, col = "red", pch = 3, cex = 0.1, xlim = c(0, 1000), ylim = c(0, 0.7), xlab = "", ylab = "")
abline(h = max(smooth.difference),v = c(split.infants, split.adults, volume.value[which.max(smooth.difference)]))



```

(7)(d) What separate harvest proportions for infants and adults would result if this cutoff is used? Show the separate harvest proportions (NOTE:  the adult harvest proportion is the "true positive rate" and the infant harvest proportion is the "false positive rate").

Code for calculating the adult harvest proportion is provided.

```{r Part_7d}
(1 - prop.adults)[which.max(smooth.difference)]  # [1] 0.7416332
(1 - prop.infants)[which.max(smooth.difference)]

```

-----

There are alternative ways to determine cutoffs. Two such cutoffs are described below.

-----

######  Section 8: (10 points)  ###################

(8)(a) Harvesting of infants in CLASS "A1" must be minimized. The smallest volume.value cutoff that produces a zero harvest of infants from CLASS "A1" may be used as a baseline for comparison with larger cutoffs. Any smaller cutoff would result in harvesting infants from CLASS "A1."  

Compute this cutoff, and the proportions of infants and adults with VOLUME exceeding this cutoff. Code for determining this cutoff is provided. Show these proportions.

```{r Part_8a}
cut.val <- volume.value[volume.value > max(mydata[mydata$CLASS == "A1" &
  mydata$TYPE == "I", "VOLUME"])][1] # [1] 206.786

(1 - prop.adults)[which(volume.value == cut.val)]
(1 - prop.infants)[which(volume.value == cut.val)]

```

(8)(b) Another cutoff is one for which the proportion of adults not harvested equals the proportion of infants harvested. This cutoff would equate these rates; effectively, our two errors:  'missed' adults and wrongly-harvested infants. This leaves for discussion which is the greater loss:  a larger proportion of adults not harvested or infants harvested?  This cutoff is 237.7383. Calculate the separate harvest proportions for infants and adults using this cutoff. Show these proportions.  Code for determining this cutoff is provided.  

```{r Part_8b}
cut2.val <- volume.value[which.min(abs(prop.adults - (1-prop.infants)))] # [1] 237.6391

(1 - prop.adults)[which(volume.value == cut2.val)]
(1 - prop.infants)[which(volume.value == cut2.val)]

```


##### Section 9: (5 points) ###########

(9)(a) Construct an ROC curve by plotting (1 - prop.adults) versus (1 - prop.infants). Each point which appears corresponds to a particular volume.value. Show the location of the cutoffs determined in (7) and (8) on this plot and label each. 

```{r Part_9}
plot((1-prop.infants), (1-prop.adults))
abline(c(0,1))
points(x = 0.1765, y = 0.7416, col = "red", cex = 2, pch = 19) # max smooth diff
points(x = 0.2872, y = 0.8260, col = "red", cex = 2, pch = 19) # zero harvest
points(x = 0.2180, y = 0.7818, col = "red", cex = 2, pch = 19) # equal harvest
text(x = 0.22, y = 0.65, labels = "max smooth diff")
text(x = 0.3, y = 0.7, labels = "equal harvest")
text(x = 0.35, y = 0.75, labels = "zero harvest")

```

(9)(b) Numerically integrate the area under the ROC curve and report your result. This is most easily done with the *auc()* function from the "flux" package.   Areas-under-curve, or AUCs, greater than 0.8 are taken to indicate good discrimination potential. 

```{r Part_9b}

flux::auc(x = (1 - prop.infants), y = (1 - prop.adults))
```


##### Section 10: (10 points) ###################

(10)(a) Prepare a table showing each cutoff along with the following:
 	1) true positive rate (1-prop.adults,
 	2) false positive rate (1-prop.infants),
 	3) harvest proportion of the total population
 	
```{r Part_10} 	
harv.prop <- c(sum(mydata$VOLUME >= volume.value[which.max(smooth.difference)])/ (total.adults + total.infants),
  sum(mydata$VOLUME >= cut.val) / (total.adults + total.infants),
  sum(mydata$VOLUME >= cut2.val)/ (total.adults + total.infants))

table <- matrix(c(0.742, 0.176, harv.prop[1], 0.826, 0.287, harv.prop[2], 0.782, 0.218, harv.prop[3]), ncol = 3, byrow = TRUE)
colnames(table) <- c("True Pos", "False Pos", "Harv. Prop.")
rownames(table) <- c("max sm. diff.", "zero harvest", "equal harvest")

as.table(table)

```
 	
**Essay Question: Based on the ROC curve, it is evident a wide range of possible "cutoffs" exist. Compare and discuss the three cutoffs determined in this assignment.**   

***Answer: (The max smooth difference cutoff has the lowest false positive rate and the smallest harvest proportion, so I would call that the most conservative option. Conversely, the zero harvest cutoff has the highest harvest proportion and the equal harvest lies in between the two. Depending on the state of the poor abalones, you might change which cutoff you use depending on how the population might change. For example you could use the max smooth difference cutoff to decrease the juveniles caught to help the population rebound.)***

**Final Essay Question:  Assume you are expected to make a presentation of your analysis to the investigators How would you do so?  Consider the following in your answer:**

1. Would you make a specific recommendation or outline various choices and tradeoffs?
2. What qualifications or limitations would you present regarding your analysis?
3. If it is necessary to proceed based on the current analysis, what suggestions would you have for implementation of a cutoff?
4)  What suggestions would you have for planning future abalone studies of this type? 

***Answer: (For part 1, I would not make a specific recommendation, I would outline the choices and tradeoffs as was discussed in the previous question. This may also include discussion of the profitability and which cutoff is most sustainable in the long run. For part 2, I would point to the previously discussed difficulty in grading abalones and how inconsistancies in this part of the data might skew our conclusions. Statistical conclusions are only as good as the data they're built on. In part 3, I would strongly suggest that the longterm survival of the abalone population be taken into consideration. Overharvesting can lead to population collapse, as can unforseen ecological disasters. If a healthy population of abalones is stressed by a slight amount of overharvesting, they become more vulerable to other outside events. In number 4, I would suggest that additional measurements be taken to reduce the false positive rate, making our analyses more accurate overall.)***